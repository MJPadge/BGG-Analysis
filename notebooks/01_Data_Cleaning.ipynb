{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc55167f-73c6-4f25-8c7f-19b70102287d",
   "metadata": {},
   "source": [
    "# Data cleaning and preparation\n",
    "Before we jump into the EDA (explortory data analysis), we need to get our data cleaned and ready.\n",
    "\n",
    "# Where is the data from?\n",
    "This project uses data that has been scraped from Board Game Geek (https://boardgamegeek.com) and made available on Kaggle.\n",
    "\n",
    "**Source** [Board Game Reviews - Jan 2025] https://www.kaggle.com/datasets/bwandowando/boardgamegeek-board-games-reviews-jan-2025\n",
    "\n",
    "**Author Credit** [bwandowando] https://www.kaggle.com/bwandowando\n",
    "\n",
    "# About the raw data\n",
    "The dataset consists of 4 csv files with some of the fields shown below:\n",
    "- boardgames.csv (Titles, Descriptions, Release Year, Ratings)\n",
    "- boardgames_reviews.csv (Pseudo Users, Comments, Post Date, Rating)\n",
    "- users.csv (Pseudo Users, Location, Badges)\n",
    "- user_game_status.csv (Pseudo Users, Ownership, Wishlisted)\n",
    "\n",
    "Before loading the raw data into Jupyter Notebooks, I completed some intial data cleaining in SQL.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4332581-ddd9-492c-9dcd-41f45a3af9f2",
   "metadata": {},
   "source": [
    "## File 1 - boardgames.csv\n",
    "The raw boardgames csv file initially looks like this:\n",
    "\n",
    "![Raw_boardgames_file](../images/Raw_boardgames_file.png)\n",
    "\n",
    "# The changes I made to this file are:\n",
    "- Renamed column headers (more for personal preference, but it also helps me to remember what fields I have)\n",
    "- Removed \"link\" and \"thumbnail\" as I don't currently need them\n",
    "\n",
    "I then ran the below SQL code:\n",
    "![boardgames_file_SQL_code](../images/boardgames_file_SQL_code.png)\n",
    "\n",
    "Which can be copied below:\n",
    "\n",
    "SELECT\n",
    "\ta.\"Rank\",\n",
    "\ta.\"Game ID\",\n",
    "\ta.\"Title\",\n",
    "\ta.\"Description\",\n",
    "\ta.\"Release Year\",\n",
    "\ta.\"Geek Rating\",\n",
    "\ta.\"Avg Rating\",\n",
    "\ta.\"Voters\"\n",
    "FROM\n",
    "\t( \tSELECT \n",
    "\t\t\tROW_NUMBER () OVER ( PARTITION BY a.\"Game ID\" ORDER BY a.\"Game ID\" ) AS \"Rn\",\n",
    "\t\t\ta.\"Rank\",\n",
    "\t\t\ta.\"Game ID\",\n",
    "\t\t\ta.\"Title\",\n",
    "\t\t\ta.\"Description\",\n",
    "\t\t\ta.\"Year\" AS \"Release Year\",\n",
    "\t\t\ta.\"Geek Rating\",\n",
    "\t\t\ta.\"Avg Rating\",\n",
    "\t\t\ta.\"Voters\"\t\n",
    "\t\tFROM \t\n",
    "\t\t\tdbo.\"BPP - Board Games\" a\n",
    "\t\tWHERE \t\n",
    "\t\t\ta.\"Geek Rating\" IS NOT NULL \n",
    "\t\tAND \t\n",
    "\t\t\ta.\"Year\" IS NOT NULL \t\t\n",
    "\t\tAND\t\t\n",
    "\t\t\ta.\"Game ID\" IS NOT NULL \t\t\t\t\n",
    "\t\tAND \t\n",
    "\t\t\ta.\"Rank\" IS NOT NULL\t\t\n",
    "\t\tAND\n",
    "\t\t \ta.\"Year\" < 2024\n",
    "\t) a\n",
    "WHERE a.\"Rn\" = 1 \n",
    "ORDER BY a.\"Rank\"\n",
    "\n",
    "# What does this do?\n",
    "\n",
    "- The Raw file consists of 161,404 \"board games\". I use quotes here as I would argue not every entry is actually a board game.\n",
    "- Firstly, any game without a \"Geek Rating\" is removed. More details about the Geek rating are below. This reduce our list of games from 161,404 to 38,059.\n",
    "- Some games do not have a release year. Perhaps no one knows when these games were released. Anyway, they were removed from the dataset reducing the total by a further 276 to 37,783 games. Games without a release year included things like Go Fish and Poker Dice etc.\n",
    "- Some games did not feature a \"Game ID\" or a \"Rank\". These were often game expansions and second editions. These were all excluded removing a further 10,943 leaving 26,840. That's still a lot of games! I have decided to remove these from the initial analysis as initially, I just want to determine the features of the original game to see if it is a classic. For a game to have a second edition or expansion, it must have garnered some level of success, which we could analyze later on. I also dont want the rating of the original game to be influences by and expansions or second editions, yet.\n",
    "- Any duplicate \"Game ID\" were also removed, just in case, but there were no duplicates, but seemed silly to remove the code which was doing no harm.\n",
    "- Lastly, I removed any games released in 2024. This is because I want to work with full years worth of data. This ensured every game on the list can contain at least one years worth of data. This removed another 1,045 games.\n",
    "\n",
    "This leaves our starting pot of games at...\n",
    "# 25,795\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd632c05-1fb1-4347-b734-e1d499cd4d5b",
   "metadata": {},
   "source": [
    "# Understanding a Geek Rating\n",
    "The dataset includes two key rating metrics for each board game.\n",
    "- **Average Rating** - The average of all user submitted scores (out of 10).\n",
    "- **Geek Rating** - This is a **Bayesian-adjusted score** used by BoardGameGeek (BGG) to provide a fairer ranking for games.\n",
    "\n",
    "A Bayesian average is used to adjust the games rating based on:\n",
    "- The number of votes received (v).\n",
    "- The average rating (r).\n",
    "- The overall average rating across all games on BGG (c) (the average rating across all games is often around 5.5).\n",
    "- A constant (m) is also introduced which determines the minimum number of votes required before a games rating is even considered.\n",
    "\n",
    "# The formula\n",
    "\n",
    "$$\n",
    "\\text{Geek Rating} = \\frac{v}{v + m} \\cdot R + \\frac{m}{v + m} \\cdot C\n",
    "$$\n",
    "\n",
    "# Example 1 : A new game with just a few votes\n",
    "Let's see a brand new game, with only a few votes. \n",
    "- **R** = 9.0 - an excellent raw average score.\n",
    "- **V** = 25 - only 25 people have rated it so far. However, this would now threaten to be the best game ever from the opinion of only 25 people.\n",
    "- **C** = 5.5 - The average review score of all games on BGG.\n",
    "- **M** = 1000 - The constant, used to determine the minimum number of votes required. Kind of works like a weighting (1000 used for illustrative purposes, the actual constant used by BGG might be different).\n",
    "\n",
    "Lets plug all of this into the formula:\n",
    "$$\n",
    "\\text{Geek Rating} = \\frac{25}{25 + 1000} \\cdot 9.0 + \\frac{1000}{25 + 1000} \\cdot 5.5\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "= 0.024 \\cdot 9.0 + 0.976 \\cdot 5.5 = 0.22 + 5.37 = \\mathbf{5.59}\n",
    "$$\n",
    "\n",
    "This reduces the rating from **9.0** to **5.59**! Our new game will need a much higher volume of positive reviews to climb to the top spot.\n",
    "\n",
    "# Example 2 : CATAN - A very popular game released in 1995\n",
    "- **R** = 7.09\n",
    "- **V** = 132623 \n",
    "- **C** = 5.5 \n",
    "- **M** = 1000\n",
    "\n",
    "Again, lets plug all of this into the formula:\n",
    "$$\n",
    "\\text{Geek Rating} = \\frac{132623}{132623 + 1000} \\cdot 7.09 + \\frac{1000}{132623 + 1000} \\cdot 5.5\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "= 0.993 \\cdot 7.09 + 0.976 \\cdot 5.5 = 7.04 + 0.04 = \\mathbf{7.08}\n",
    "$$\n",
    "\n",
    "Due to the high volume of ratings for CATAN, the Geek Rating does not differ much from the non-adjusted average, going from **7.09** to **7.08**. \n",
    "\n",
    "# Why use this calculation?\n",
    "The geek rating is designed to prevent games with just a few (potentially biased) scores from ranking too high or too low.\n",
    "In this project I will be using the Geek Rating to assess a game's **overall perceived quality**, since it accounts for both rating score and the number of votes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7b022-cd70-475b-858e-dfd3aaf3ae46",
   "metadata": {},
   "source": [
    "## Importing the cleaned boardgames dataset\n",
    "After performing the initial data cleaining in SQL, I exported the clean result to a CSV file and will now load it into the notebook using Python and pandas. \n",
    "\n",
    "To recap, in the cleaned dataset:\n",
    "- Any duplicate game ID's have been removed\n",
    "- The game must have a Geek Rating\n",
    "- The game must have a Release Year\n",
    "- The game must have an ID and a Rank\n",
    "- The game must have been released before 2024\n",
    "\n",
    "This dataset will be used for further cleaning and feature engineering in this notebook. Below is an example of the first 10 rows of the SQL cleaned and formatted data so that we can see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27a9d0f-b5d0-4c6b-aa6d-e05c779051d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/cleaned/Boardgames_SQL_Cleaned_File.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/cleaned/Boardgames_SQL_Cleaned_File.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Show the top 10 rows\u001b[39;00m\n\u001b[1;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/cleaned/Boardgames_SQL_Cleaned_File.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../data/cleaned/Boardgames_SQL_Cleaned_File.csv') \n",
    "\n",
    "# Show the top 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99548f-7a68-4cd8-9613-01ef59186d44",
   "metadata": {},
   "source": [
    "## File 2 - boardgames_reviews.csv\n",
    "The raw boardgames reviews file looks like this:\n",
    "\n",
    "![Raw_boardgames_reviews_file](../images/Raw_boardgames_reviews_file.png)\n",
    "\n",
    "And it is a big file. 29,618,236 rows to be exact. This consists of every review and vote cast for every board game on the website. \n",
    "\n",
    "![SQL_boardgame_review_count_query](../images/SQL_boardgame_review_count_query.png)\n",
    "\n",
    "![SQL_boardgame_review_count_result](../images/SQL_boardgame_review_count_result.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3075b08-6d06-4f01-baa0-b6c9aab268d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
